{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026f9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "#Load text file of scraped Elon Musk tweets and split text on \\n \n",
    "data_path = \"elon_tweets.txt\"\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# Preprocess tweets by removing reply tweets (with @) and https:\\\\ links\n",
    "# Append preprocessed tweets to a list called elon_tweets\n",
    "elon_tweets = []\n",
    "for line in lines:\n",
    "    if '@' in line:\n",
    "        pass\n",
    "    else:\n",
    "        tweet = re.sub(r'http\\S+', '', line)\n",
    "        elon_tweets.append(tweet.lower())\n",
    "\n",
    "\n",
    "# Begin creating the ChatBot\n",
    "class ChatBot:\n",
    " \n",
    "    #Potential negative and exit responses to end program\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\", 'nothing', 'not')\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "    \n",
    "    \n",
    "    # Predtermined conjuction phrases to make ChatBot more 'human'\n",
    "    topic_change_phrases = ['Good, you were starting to bore me!\\n',\n",
    "                            'Excellent, I have so much more knowledge to share!\\n',\n",
    "                            'Direct and to the point, I love it\\n',\n",
    "                           'Phew! I was running out of things to say...\\n',\n",
    "                           \"Let's have a quick time out and reset\\n\"]\n",
    "    \n",
    "    new_topic_phrases = ['What field are you interested in now?\\n',\n",
    "                         'Perfect! What would you like to ask me about?\\n',\n",
    "                         'Love your thirst for knowledge, keep drinking...\\n',\n",
    "                         'I am an open book, what chapter is next?\\n',\n",
    "                        'Ask away, today really is Elon Musk unfiltered...\\n',\n",
    "                        'I am a transparent person, ask me anything']\n",
    "    \n",
    "    unknown_phrases = [\"I'm inteligent but I don't know everything you know\\n\",\n",
    "                       \"For once in my life I am speechless...\\n\",\n",
    "                       \"If I told you that, I would have to kill you\\n\",\n",
    "                       \"We are working on some incredible things at the moment and I'll get back to you when I know\\n\",\n",
    "                       \"Unfortunately, some things I can't disclose right now\\n\",\n",
    "                      'Woah ok, this topic got a bit personal lets move on']\n",
    "\n",
    "    \n",
    "    \n",
    "    def start_chat(self):\n",
    "        \n",
    "        #Greet user and save name\n",
    "        user_name = input(\"Elon: Welcome to the future friend, my name is Elon Muskâ€¦ what's your name?\\n\\n\")\n",
    "        \n",
    "        # Ask if user wants to start to chat\n",
    "        user_response = input(f'\\nElon: Greetings {user_name}\\nElon: I have technical expertise spanning over many industries along with some controversial opinions. Would you like me to share my infinte knowledge with you?\\n\\n')\n",
    "        \n",
    "        # If response negative, end conversation\n",
    "        words = word_tokenize(user_response)\n",
    "        for word in words:\n",
    "            if word in self.negative_responses:\n",
    "                print('\\nElon: Ok, have a great day!\\n')\n",
    "                break\n",
    "                \n",
    "        # Otherwise continue to chat\n",
    "            else:\n",
    "                self.chat(user_response)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def chat(self, reply):\n",
    "        # If exit command called in reply, end chat\n",
    "        if self.make_exit(reply) == True:\n",
    "            pass\n",
    "        \n",
    "        # Otherwise determine intented topic\n",
    "        else:\n",
    "            self.topic_intent(reply)\n",
    "        \n",
    "            \n",
    "    \n",
    "    def change_chat(self, reply, topic):\n",
    "        \n",
    "        words = word_tokenize(reply)\n",
    "        \n",
    "        # End conversation if exit command used\n",
    "        for word in words:\n",
    "            if word in self.exit_commands:\n",
    "                self.chat(reply)\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                # If negative, new intended topic determined through .topic_intent()\n",
    "                for word in words:\n",
    "                    if word in self.negative_responses:\n",
    "                        print('\\nElon: ' + random.choice(self.topic_change_phrases))\n",
    "                        self.topic_intent(topic)\n",
    "                        break\n",
    "                    \n",
    "                    # If positive, specialize conversation towards initial intended topic using .deeper_topic_intent()\n",
    "                    else:\n",
    "                        return input(self.deeper_topic_intent(topic))     \n",
    "                    \n",
    "                    \n",
    "            \n",
    "    def topic_intent(self, topic):\n",
    "        \n",
    "        # Takes user input as topic_sentence and extracts most popular noun in sentence, saved as topic\n",
    "        topic_sentence = input('Elon: ' + random.choice(self.new_topic_phrases) + '\\n')\n",
    "        topic = self.extract_pop_noun(elon_tweets, topic_sentence)\n",
    "        \n",
    "        #M ore conjunction phrases that use user_input\n",
    "        deeper_topic_phrases = [f'What more do you want to know about {topic}\\n',\n",
    "                                f'{topic} is a rabbit hole of knowledge, lets explore it!\\n',\n",
    "                               f'What other {topic} related questions do you have?\\n',\n",
    "                               f\"Let's continue this {topic} interrogation then...\\n\",\n",
    "                               f\" I've got some juicy {topic} gossip if you ask me the right questions\\n\"]\n",
    "        still_interested_phrases = [f'Am I still entertaining you with {topic}?\\n',\n",
    "                                    f'Would you like to know more about {topic}?\\n',\n",
    "                                    f'I have vast opinions about {topic}, would you like to continue discussing?',\n",
    "                                   f\"Are you as captivated with {topic} as I am?\\n\",\n",
    "                                    f\"Would you like to continue this {topic} cross examination?\\n\"]\n",
    "        \n",
    "        # Refines tweets to only ones which contain user selected topic\n",
    "        topic_tweets = []\n",
    "        for tweet in elon_tweets:\n",
    "            if topic in tweet:\n",
    "                topic_tweets.append(tweet)\n",
    "        \n",
    "        # If no tweets are found about intended topic, random 'unknown_phrases' printed and .topic_intent() restarted\n",
    "        if len(topic_tweets) == 0:\n",
    "            print('\\nElon: ' + random.choice(self.unknown_phrases))\n",
    "            self.topic_intent(topic)\n",
    "        \n",
    "        # If tweets are found, one is printed at random and user is asked if they want to continue with intended topic\n",
    "        # user reply and topic is fed into .change_chat()\n",
    "        else:\n",
    "            reply = input('\\nElon: ' + random.choice(topic_tweets) + '\\n' + 'Elon: ' +  random.choice(still_interested_phrases) + '\\n')\n",
    "\n",
    "        self.change_chat(reply, topic)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def deeper_topic_intent(self, topic):\n",
    "        \n",
    "        # More conjunction phrases that use user_input\n",
    "        deeper_topic_phrases = [f'What more do you want to know about {topic}\\n',\n",
    "                                f'{topic} is a rabbit hole of knowledge, lets explore it!\\n',\n",
    "                               f'What other {topic} related questions do you have?\\n',\n",
    "                               f\"Let's continue this {topic} interrogation then...\\n\",\n",
    "                               f\" I've got some juicy {topic} gossip if you ask me the right questions\\n\"]\n",
    "        still_interested_phrases = [f'Am I still entertaining you with {topic}?\\n',\n",
    "                                    f'Would you like to know more about {topic}?\\n',\n",
    "                                    f'I have vast opinions about {topic}, would you like to continue discussing?',\n",
    "                                   f\"Are you as captivated with {topic} as I am?\\n\",\n",
    "                                    f\"Would you like to continue this {topic} cross examination?\\n\"]\n",
    "        \n",
    "        # Again user input is taken as topic_sentence and extracts most popular noun in sentence, saved as deep_topic\n",
    "        deep_topic_sentence = input('\\nElon: ' + random.choice(deeper_topic_phrases) + '\\n')\n",
    "        deep_topic = self.extract_pop_noun(elon_tweets, deep_topic_sentence)\n",
    "        \n",
    "        # Inital topic tweet subset found again\n",
    "        topic_tweets = []\n",
    "        for tweet in elon_tweets:\n",
    "            if topic in tweet:\n",
    "                topic_tweets.append(tweet)\n",
    "        \n",
    "        # This time any inital topic tweets which also contain the deep_topic are collated\n",
    "        deep_lst = []\n",
    "        for tweet in topic_tweets:\n",
    "            if deep_topic in tweet:\n",
    "                deep_lst.append(tweet)\n",
    "        \n",
    "        # If no tweets are found about both topics, random 'unknown_phrases' printed\n",
    "        if len(deep_lst) == 0:\n",
    "            reply = input('\\nElon: ' + random.choice(self.unknown_phrases) + 'Elon: ' + random.choice(still_interested_phrases)+ '\\n')\n",
    "        \n",
    "        #Otherwise random tweet is printed\n",
    "        else:\n",
    "            reply = input('\\nElon: ' + random.choice(deep_lst) + '\\n' + 'Elon: ' + random.choice(still_interested_phrases) + '\\n\\n')\n",
    "        \n",
    "        # Both paths lead to user being asked if they would like to continue\n",
    "        # Reply and inital topic fed back to .change_chat()\n",
    "        self.change_chat(reply, topic)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def extract_pop_noun(self, tweets, topic_sentence):\n",
    "        #Function takes a user sentence and extracts only the most popular noun to use as intended topic\n",
    "        \n",
    "        #All english stopwords such as 'the', 'and', 'in' ect.\n",
    "        stops = stopwords.words('english')\n",
    "        \n",
    "        # All words in sentence are POS tagged and only nouns are extracted\n",
    "        nouns = [token for token, pos in pos_tag(word_tokenize(topic_sentence)) if pos.startswith('N')]\n",
    "        \n",
    "        #All tweets tokenized into singular words and added to word list\n",
    "        word_lst = []\n",
    "        for tweet in tweets:\n",
    "            words = tweet.split()\n",
    "            for word in words:\n",
    "                word_lst.append(word)\n",
    "        \n",
    "        # Counter function creates dictionary with keys as words and values as number of times word has appeared\n",
    "        count_dict = Counter(word_lst)\n",
    "        for stopword in stops:\n",
    "            count_dict.pop(stopword, None)\n",
    "        \n",
    "        # If there is more than one noun in user sentence, key with greatest value in dictionary extracted\n",
    "        # Saved and returned as pop_noun\n",
    "        if len(nouns) > 1:\n",
    "            noun_max = 0\n",
    "            for noun in nouns:\n",
    "                if count_dict[noun] > noun_max:\n",
    "                    noun_max = count_dict[noun]\n",
    "\n",
    "            for word, count in count_dict.items(): \n",
    "                if count == noun_max and word in nouns:\n",
    "                    pop_noun = word\n",
    "\n",
    "            return pop_noun\n",
    "        \n",
    "        # If there are no nouns in sentence, function returns gibberish string to force an unknown_phrase path\n",
    "        elif len(nouns) == 0:\n",
    "            return 'poiuytrewq'\n",
    "        \n",
    "        #If only one, that one is chosen\n",
    "        else:\n",
    "            pop_noun = nouns[0]\n",
    "            return pop_noun\n",
    "        \n",
    "        \n",
    "        \n",
    "    def make_exit(self, reply):\n",
    "        \n",
    "        # If user reply contains an exit command, goodbye message printed and script ends\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print('\\nI survived your grilling! Have a great day now')\n",
    "                return True\n",
    "        \n",
    "        # If not script continues\n",
    "        return False\n",
    "\n",
    "\n",
    "#Chatbot initialized and function called to begin script\n",
    "elon_bot = ChatBot()\n",
    "elon_bot.start_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
